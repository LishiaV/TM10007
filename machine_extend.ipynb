{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course: TM10007 - Machine learning\n",
    "Editors: Lishia Vergeer, Amy Roos, Maaike Pruijt, Hilde Roording.\n",
    "\n",
    "Description: The aim of this code is to predict the tumor grade of gliomaâ€™s(high or low) before surgery, \n",
    "based on features extracted from a combination of four MRI images: \n",
    "T2-weighted, T2-weighted FLAIR and T1-weighted before and after injection of contrast agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hilde\\miniconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# General packages\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets as ds\n",
    "\n",
    "# Import code\n",
    "from brats.load_data import load_data\n",
    "\n",
    "# Performance \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import decomposition\n",
    "import seaborn\n",
    "\n",
    "\n",
    "# Pipeline and gridsearch\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# scaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "#Machine learning classifiers\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import feature_selection \n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples in data_brats: 167\n",
      "The number of columns in data_brats: 725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hilde\\Python\\TM10007_Machine_Learning\\TM10007\\brats\\load_data.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(data2)\n"
     ]
    }
   ],
   "source": [
    "data_brats = load_data()\n",
    "\n",
    "# Convert to dataframe\n",
    "X = pd.DataFrame(data_brats)\n",
    "\n",
    "# Print data \n",
    "print(f'The number of samples in data_brats: {len(X.index)}')\n",
    "print(f'The number of columns in data_brats: {len(X.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data in X and y\n",
    "Split in X (data) and y (label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split column label from dataset X\n",
    "y = X.pop('label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data in train and test set\n",
    "This function creates a panda dataframe and splits the data into test and train components.\n",
    "This is done with test_size variable and the function train_test_split from the sklearn module.\n",
    "Returns a train set with the data of 80% and a test set of 20% of the subjects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data in train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 704)\n",
      "(133, 704)\n"
     ]
    }
   ],
   "source": [
    "# infinity to NaN\n",
    "X_train[X_train==np.inf]=np.nan\n",
    "\n",
    "# non-numeric features to NaN\n",
    "X_train = X_train.replace(['#DIV/0!'], np.nan)\n",
    "X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "X_test  = X_test.replace(['#DIV/0!'], np.nan)\n",
    "X_test = X_test.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# If the total number of NaN observations in a column are greater than 40%, delete the entire column.\n",
    "perc = 40.0\n",
    "min_count = int(((100-perc)/100)*X_train.shape[0] + 1)\n",
    "X_train_drop = X_train.dropna(axis=1, thresh=min_count)\n",
    "X_labels = X_train_drop.keys()\n",
    "\n",
    "X_test_drop = X_test[X_labels]\n",
    "print(X_test_drop.shape)\n",
    "print(X_train_drop.shape)\n",
    "\n",
    "# fill the NaN observations.\n",
    "data_fill_train = X_train_drop.fillna(X_train_drop.mean()) \n",
    "data_fill_test = X_test_drop.fillna(X_test_drop.mean()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "##### building a pipeline to define each transformer type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputation', SimpleImputer(missing_values = np.NaN, strategy='most_frequent')),   # kan ook strategy = 'most frequent'\n",
    "    ('robust', RobustScaler())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "pca = decomposition.PCA()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features), ('pca', pca)]) \n",
    "\n",
    "#preprocessor = ColumnTransformer(\n",
    " #   transformers=[\n",
    "  #      ('num', numeric_transformer, numeric_features)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop some classifiers and check performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hilde\\Python\\TM10007_Machine_Learning\\TM10007\\machine_extend.ipynb Cell 16'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hilde/Python/TM10007_Machine_Learning/TM10007/machine_extend.ipynb#ch0000025?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m classifier \u001b[39min\u001b[39;00m classifiers:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hilde/Python/TM10007_Machine_Learning/TM10007/machine_extend.ipynb#ch0000025?line=11'>12</a>\u001b[0m     pipe \u001b[39m=\u001b[39m Pipeline(steps\u001b[39m=\u001b[39m[(\u001b[39m'\u001b[39m\u001b[39mpreprocessor\u001b[39m\u001b[39m'\u001b[39m, preprocessor),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hilde/Python/TM10007_Machine_Learning/TM10007/machine_extend.ipynb#ch0000025?line=12'>13</a>\u001b[0m                       (\u001b[39m'\u001b[39m\u001b[39mclassifier\u001b[39m\u001b[39m'\u001b[39m, classifier)])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/hilde/Python/TM10007_Machine_Learning/TM10007/machine_extend.ipynb#ch0000025?line=13'>14</a>\u001b[0m     pipe\u001b[39m.\u001b[39;49mfit(data_fill_train, y_train)   \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hilde/Python/TM10007_Machine_Learning/TM10007/machine_extend.ipynb#ch0000025?line=14'>15</a>\u001b[0m     \u001b[39mprint\u001b[39m(classifier)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hilde/Python/TM10007_Machine_Learning/TM10007/machine_extend.ipynb#ch0000025?line=15'>16</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmodel score: \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m pipe\u001b[39m.\u001b[39mscore(data_fill_test, y_test))\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\pipeline.py:390\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=363'>364</a>\u001b[0m \u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=364'>365</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=365'>366</a>\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=386'>387</a>\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=387'>388</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=388'>389</a>\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m--> <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=389'>390</a>\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps)\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=390'>391</a>\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=391'>392</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\pipeline.py:348\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=345'>346</a>\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=346'>347</a>\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=347'>348</a>\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=348'>349</a>\u001b[0m     cloned_transformer,\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=349'>350</a>\u001b[0m     X,\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=350'>351</a>\u001b[0m     y,\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=351'>352</a>\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=352'>353</a>\u001b[0m     message_clsname\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=353'>354</a>\u001b[0m     message\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(step_idx),\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=354'>355</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps[name],\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=355'>356</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=356'>357</a>\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=357'>358</a>\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=358'>359</a>\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=359'>360</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/joblib/memory.py?line=347'>348</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/joblib/memory.py?line=348'>349</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=890'>891</a>\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=891'>892</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=892'>893</a>\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit_transform(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=893'>894</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/pipeline.py?line=894'>895</a>\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:671\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/compose/_column_transformer.py?line=668'>669</a>\u001b[0m \u001b[39m# set n_features_in_ attribute\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/compose/_column_transformer.py?line=669'>670</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/compose/_column_transformer.py?line=670'>671</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_transformers()\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/compose/_column_transformer.py?line=671'>672</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_column_callables(X)\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/compose/_column_transformer.py?line=672'>673</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_remainder(X)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:324\u001b[0m, in \u001b[0;36mColumnTransformer._validate_transformers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/compose/_column_transformer.py?line=320'>321</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformers:\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/compose/_column_transformer.py?line=321'>322</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/compose/_column_transformer.py?line=323'>324</a>\u001b[0m names, transformers, _ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformers)\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/compose/_column_transformer.py?line=325'>326</a>\u001b[0m \u001b[39m# validate names\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/hilde/miniconda3/lib/site-packages/sklearn/compose/_column_transformer.py?line=326'>327</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_names(names)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "# Beste classifier gebruiken! Dit gebruiken om keuze te onderbouwen\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "    NuSVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier()]\n",
    "    \n",
    "for classifier in classifiers:\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', classifier)])\n",
    "    pipe.fit(data_fill_train, y_train)   \n",
    "    print(classifier)\n",
    "    print(\"model score: %.3f\" % pipe.score(data_fill_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparametersearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__max_depth': 7, 'classifier__max_features': 'sqrt', 'classifier__n_estimators': 500}\n",
      "0.8951566951566953\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter suggestions\n",
    "param_grid = { \n",
    "    'classifier__n_estimators': [200, 500],\n",
    "    'classifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'classifier__max_depth' : [4,5,6,7,8]}                        # kan ook nog, maar deed het niet: 'classifier__criterion' :['gini', 'entropy']\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Gridsearch with 5-fold cross validation\n",
    "Gridsearch_CV = GridSearchCV(pipe, param_grid, n_jobs= 1, cv=5)   # Hier kunnen we kiezen voor GridSearh of randomgridsearch\n",
    "                  \n",
    "Gridsearch_CV.fit(X_train, y_train)  \n",
    "\n",
    "#Kijken welke parameters het best zijn en die uiteindelijk gebruiken!\n",
    "print(Gridsearch_CV.best_params_)    \n",
    "print(Gridsearch_CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'static_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[1;32mc:\\Users\\hilde\\Python\\TM10007_Machine_Learning\\TM10007\\code.ipynb Cell 23'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hilde/Python/TM10007_Machine_Learning/TM10007/code.ipynb#ch0000022?line=0'>1</a>\u001b[0m \u001b[39m#create pipeline with best parameters and best classifier : voor nu gekozen voor RF \u001b[39;00m\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hilde/Python/TM10007_Machine_Learning/TM10007/code.ipynb#ch0000022?line=1'>2</a>\u001b[0m \u001b[39m# Error bij andere classifiers en niet bij xgb?  .XGBClassifier opzoeken bij RF enzo\u001b[39;00m\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hilde/Python/TM10007_Machine_Learning/TM10007/code.ipynb#ch0000022?line=2'>3</a>\u001b[0m hyperparams_after_gridsearch\u001b[39m=\u001b[39m Gridsearch_CV\u001b[39m.\u001b[39mbest_params_\n",
      "\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hilde/Python/TM10007_Machine_Learning/TM10007/code.ipynb#ch0000022?line=3'>4</a>\u001b[0m params_after_grid \u001b[39m=\u001b[39m { \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mstatic_params, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhyperparams_after_gridsearch}\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hilde/Python/TM10007_Machine_Learning/TM10007/code.ipynb#ch0000022?line=4'>5</a>\u001b[0m pipe_after_grid \u001b[39m=\u001b[39m Pipeline([(\u001b[39m'\u001b[39m\u001b[39mclassifier\u001b[39m\u001b[39m'\u001b[39m, xgb\u001b[39m.\u001b[39mXGBClassifier(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams_after_grid))])\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hilde/Python/TM10007_Machine_Learning/TM10007/code.ipynb#ch0000022?line=6'>7</a>\u001b[0m \u001b[39m#fit pipe with hyperparameters on complete train set\u001b[39;00m\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'static_params' is not defined"
     ]
    }
   ],
   "source": [
    "#create pipeline with best parameters and best classifier : voor nu gekozen voor RF \n",
    "# Error bij andere classifiers en niet bij xgb?  .XGBClassifier opzoeken bij RF enzo\n",
    "hyperparams_after_gridsearch= Gridsearch_CV.best_params_\n",
    "params_after_grid = { **static_params, **hyperparams_after_gridsearch}\n",
    "pipe_after_grid = Pipeline([('classifier', xgb.XGBClassifier(**params_after_grid))])\n",
    "\n",
    "#fit pipe with hyperparameters on complete train set\n",
    "bst= pipe_after_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "score_train = roc_auc_score(y_train, bst.predict_proba(X_train)[:, 1])\n",
    "print(score_train)\n",
    "\n",
    "#TEST WERKT NOG NIET\n",
    "#score_test = roc_auc_score(y_test, bst.predict_proba(X_test)[:, 1])\n",
    "# print(score_test)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75db1649061a4efd24d53350561334aa22b1bfcd544c077d6d1bdd9329699d44"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
