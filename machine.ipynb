{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course: TM10007 - Machine learning\n",
    "Editors: Lishia Vergeer, Amy Roos, Maaike Pruijt, Hilde Roording.\n",
    "\n",
    "Description: The aim of this code is to predict the tumor grade of gliomaâ€™s(high or low) before surgery, \n",
    "based on features extracted from a combination of four MRI images: \n",
    "T2-weighted, T2-weighted FLAIR and T1-weighted before and after injection of contrast agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General packages\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets as ds\n",
    "\n",
    "# Import code\n",
    "from brats.load_data import load_data\n",
    "\n",
    "# Performance \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import decomposition\n",
    "import seaborn\n",
    "\n",
    "\n",
    "# Pipeline and gridsearch\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# scaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "#Machine learning classifiers\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import feature_selection \n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples in data_brats: 167\n",
      "The number of columns in data_brats: 725\n"
     ]
    }
   ],
   "source": [
    "data_brats = load_data()\n",
    "\n",
    "# Convert to dataframe\n",
    "X = pd.DataFrame(data_brats)\n",
    "\n",
    "# Print data \n",
    "print(f'The number of samples in data_brats: {len(X.index)}')\n",
    "print(f'The number of columns in data_brats: {len(X.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data in X and y\n",
    "Split in X (data) and y (label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split column label from dataset X\n",
    "y = X.pop('label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data in train and test set\n",
    "This function creates a panda dataframe and splits the data into test and train components.\n",
    "This is done with test_size variable and the function train_test_split from the sklearn module.\n",
    "Returns a train set with the data of 80% and a test set of 20% of the subjects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data in train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infinity to NaN\n",
    "X_train[X_train==np.inf]=np.nan\n",
    "X_test[X_test==np.inf]=np.nan\n",
    "\n",
    "# non-numeric features to NaN\n",
    "X_train = X_train.replace(['#DIV/0!'], np.nan)\n",
    "X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "X_test  = X_test.replace(['#DIV/0!'], np.nan)\n",
    "X_test = X_test.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# If the total number of NaN observations in a column are greater than 40%, delete the entire column.\n",
    "perc = 40.0\n",
    "min_count = int(((100-perc)/100)*X_train.shape[0] + 1)\n",
    "X_train_drop = X_train.dropna(axis=1, thresh=min_count)\n",
    "X_labels = X_train_drop.keys()\n",
    "\n",
    "X_test_drop = X_test[X_labels]\n",
    "\n",
    "# fill the NaN observations.\n",
    "data_fill_train = X_train_drop.fillna(X_train_drop.mean()) \n",
    "data_fill_test = X_test_drop.fillna(X_test_drop.mean()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# robustscaler\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(data_fill_train)\n",
    "X_train_scaled = scaler.transform(data_fill_train)\n",
    "X_test_scaled = scaler.transform(data_fill_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a PCA\n",
    "pca = decomposition.PCA(n_components=5)\n",
    "pca.fit(X_train_scaled) \n",
    "X_train_pca = pca.transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59259259 0.7037037  0.7037037  0.65384615 0.88461538]\n",
      "KNeighborsClassifier() mean: 0.7076923076923076\n",
      "[0.59259259 0.85185185 0.62962963 0.65384615 0.76923077]\n",
      "RandomForestClassifier() mean: 0.6994301994301994\n",
      "[0.55555556 0.7037037  0.55555556 0.61538462 0.57692308]\n",
      "SVC(C=0.025, probability=True) mean: 0.6014245014245014\n",
      "[0.62962963 0.74074074 0.59259259 0.53846154 0.65384615]\n",
      "NuSVC(probability=True) mean: 0.631054131054131\n",
      "[0.51851852 0.66666667 0.66666667 0.65384615 0.84615385]\n",
      "DecisionTreeClassifier() mean: 0.6703703703703703\n",
      "[0.62962963 0.62962963 0.62962963 0.61538462 0.80769231]\n",
      "AdaBoostClassifier() mean: 0.6623931623931624\n",
      "[0.59259259 0.7037037  0.66666667 0.65384615 0.88461538]\n",
      "GradientBoostingClassifier() mean: 0.7002849002849002\n"
     ]
    }
   ],
   "source": [
    "# Create a cross-validation object\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle= True, random_state = 1)\n",
    "\n",
    "X = X_train_pca\n",
    "\n",
    "y = y_train.values\n",
    "y = np.where(y=='GBM', 1, y)\n",
    "y = np.where(y=='LGG', 2, y)\n",
    "y = y.tolist()\n",
    "\n",
    "classifiers = (KNeighborsClassifier(), RandomForestClassifier(), SVC(kernel=\"rbf\", C=0.025, probability=True), NuSVC(probability=True), DecisionTreeClassifier(), AdaBoostClassifier(), GradientBoostingClassifier() )\n",
    "\n",
    "for cls in classifiers:\n",
    "\n",
    "    list_scores = cross_val_score(cls, X, y, scoring = 'accuracy', cv=cv)\n",
    "    mean = np.mean(list_scores)\n",
    "\n",
    "    print(list_scores)\n",
    "    print(f'{cls} mean:', mean)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct classifiers\n",
    "clsfs = [RandomForestClassifier(n_estimators=1, random_state=42),\n",
    "         RandomForestClassifier(n_estimators=5, random_state=42),\n",
    "         RandomForestClassifier(n_estimators=200, random_state=42)]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75db1649061a4efd24d53350561334aa22b1bfcd544c077d6d1bdd9329699d44"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
